{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c743324d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 150)\n",
      "6540\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load matrices from TSV files\n",
    "matrix1 = np.loadtxt(\"output_factors.lhs.tsv\", delimiter=\"\\t\")\n",
    "matrix2 = np.loadtxt(\"output_factors.rhs.tsv\", delimiter=\"\\t\")\n",
    "matrix3 = np.loadtxt(\"matrix.tsv\", delimiter=\"\\t\")\n",
    "\n",
    "# Perform matrix multiplication\n",
    "result = np.matmul(matrix1, matrix2)\n",
    "\n",
    "# Perform subtraction\n",
    "final_result = result - matrix3\n",
    "print(matrix3.shape)\n",
    "# Save final result to a new file\n",
    "# np.savetxt(\"final_result.tsv\", final_result, delimiter=\"\\t\", fmt=\"%d\")\n",
    "count = np.count_nonzero(final_result == -1)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dbbcaf",
   "metadata": {},
   "source": [
    "# SGD simple works "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "29b5387b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.  0.  4.  ... 0.  0.  0. ]\n",
      " [0.  0.  0.  ... 0.  0.  0. ]\n",
      " [0.  0.  0.  ... 0.  0.  0. ]\n",
      " ...\n",
      " [2.5 2.  2.  ... 0.  0.  0. ]\n",
      " [3.  0.  0.  ... 0.  0.  0. ]\n",
      " [5.  0.  0.  ... 0.  0.  0. ]]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [252]\u001b[0m, in \u001b[0;36m<cell line: 86>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m P \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(N,K)\n\u001b[1;32m     82\u001b[0m Q \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(M,K)\n\u001b[0;32m---> 86\u001b[0m nP, nQ \u001b[38;5;241m=\u001b[39m \u001b[43mmatrix_factorization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m nR \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mdot(nP, nQ\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mprint\u001b[39m(nR)\n",
      "Input \u001b[0;32mIn [252]\u001b[0m, in \u001b[0;36mmatrix_factorization\u001b[0;34m(R, P, Q, K, steps, alpha, beta)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(R)):\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(R[i])):\n\u001b[0;32m---> 34\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mR\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m[j] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     36\u001b[0m             e \u001b[38;5;241m=\u001b[39m e \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mpow\u001b[39m(R[i][j] \u001b[38;5;241m-\u001b[39m numpy\u001b[38;5;241m.\u001b[39mdot(P[i,:],Q[:,j]), \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     38\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(K):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "def matrix_factorization(R, P, Q, K, steps=5000, alpha=0.0002, beta=0.02):\n",
    "    '''\n",
    "    R: rating matrix\n",
    "    P: |U| * K (User features matrix)\n",
    "    Q: |D| * K (Item features matrix)\n",
    "    K: latent features\n",
    "    steps: iterations\n",
    "    alpha: learning rate\n",
    "    beta: regularization parameter'''\n",
    "    Q = Q.T\n",
    "\n",
    "    for step in range(steps):\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    # calculate error\n",
    "                    eij = R[i][j] - numpy.dot(P[i,:],Q[:,j])\n",
    "\n",
    "                    for k in range(K):\n",
    "                        # calculate gradient with a and beta parameter\n",
    "                        P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j] - beta * P[i][k])\n",
    "                        Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k] - beta * Q[k][j])\n",
    "\n",
    "        eR = numpy.dot(P,Q)\n",
    "\n",
    "        e = 0\n",
    "\n",
    "        for i in range(len(R)):\n",
    "\n",
    "            for j in range(len(R[i])):\n",
    "\n",
    "                if R[i][j] > 0:\n",
    "\n",
    "                    e = e + pow(R[i][j] - numpy.dot(P[i,:],Q[:,j]), 2)\n",
    "\n",
    "                    for k in range(K):\n",
    "\n",
    "                        e = e + (beta/2) * (pow(P[i][k],2) + pow(Q[k][j],2))\n",
    "        # 0.001: local minimum\n",
    "        if e < 0.001:\n",
    "\n",
    "            break\n",
    "\n",
    "    return P, Q.T\n",
    "\n",
    "\n",
    "# Reads the movie lens data and creates a matrix out of it \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "ratings = pd.read_csv(\"/home/cris-musa/Documents/Dataset/ratings.csv\")\n",
    "movies = pd.read_csv(\"/home/cris-musa/Documents/Dataset/movies.csv\")\n",
    "# print(ratings)\n",
    "# print(movies)\n",
    "\n",
    "R = np.zeros(shape=(610,193609),dtype=float)\n",
    "for i in range(100835):\n",
    "    user = ratings[\"userId\"][i]-1\n",
    "    movie = ratings[\"movieId\"][i]-1\n",
    "    R[user][movie]=ratings[\"rating\"][i]\n",
    "print(R)\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "K = 3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "R = numpy.array(R)\n",
    "# N: num of User\n",
    "N = len(R)\n",
    "# M: num of Movie\n",
    "M = len(R[0])\n",
    "\n",
    " \n",
    "P = numpy.random.rand(N,K)\n",
    "Q = numpy.random.rand(M,K)\n",
    "\n",
    " \n",
    "\n",
    "nP, nQ = matrix_factorization(R, P, Q, K)\n",
    "\n",
    "nR = numpy.dot(nP, nQ.T)\n",
    "print(nR)\n",
    "\n",
    "# print(R-nR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e990efda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b8b3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.linalg.norm(R-nR)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9731ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0f4c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "682a1ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def matrix_factorization_PALM(R, k, max_iter=1000, tol=1e-4):\n",
    "    \"\"\"\n",
    "    Matrix factorization using Proximal Alternating Linear Minimization (PALM)\n",
    "    \n",
    "    Parameters:\n",
    "        R (np.ndarray): Input matrix to factorize\n",
    "        k (int): Number of latent factors\n",
    "        max_iter (int): Maximum number of iterations\n",
    "        tol (float): Tolerance for convergence\n",
    "        lambda_ (float): Regularization term\n",
    "        \n",
    "    Returns:\n",
    "        (np.ndarray, np.ndarray): The two factor matrices\n",
    "    \"\"\"\n",
    "    m, n = R.shape\n",
    "    X = np.random.rand(m, k)\n",
    "    Y = np.random.rand(k, n)\n",
    "    \n",
    "    # Set the step size\n",
    "    eta = 1 / (np.linalg.norm(X, 2) * np.linalg.norm(Y, 2))\n",
    "#     print(eta)\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "#         print(i)\n",
    "    #         X_prev = X.copy()\n",
    "    #         Y_prev = Y.copy()\n",
    "\n",
    "        # Minimize with respect to X\n",
    "\n",
    "        for j in range(m):\n",
    "            YYt = Y @ Y.T\n",
    "            RYt = R @ Y.T\n",
    "            L = max(np.linalg.norm(YYt), 1e-4)\n",
    "            eta = 1/(1.1*L)\n",
    "            grad_X = X @ YYt - RYt\n",
    "            X = X-grad_X * eta\n",
    "\n",
    "\n",
    "        # Minimize with respect to Y\n",
    "        for j in range(n):\n",
    "            XtX = X.T @ X\n",
    "            RtX = R.T @ X\n",
    "            L = max(np.linalg.norm(XtX), 1e-4)\n",
    "            eta = 1/(1.1*L)\n",
    "            grad_Yt = Y.T @ XtX - RtX\n",
    "            Yt = Y.T-grad_Yt *eta\n",
    "\n",
    "\n",
    "        \n",
    "        ell = np.linalg.norm(R - X @ Y)**2\n",
    "        ell0 = ell\n",
    "        # Check for convergence\n",
    "    #         if (abs(ell - ell0) < tol):\n",
    "    #             break   \n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0f79e884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.65466402  3.44029303  0.33928606  0.02295611]\n",
      " [ 3.41104293  0.75090264  0.57863917 -0.66631034]\n",
      " [-0.19626591  2.52520322  1.17530859  1.6154575 ]\n",
      " [-0.06222382  1.35430357  1.04361478  0.99469687]\n",
      " [-0.08631211  3.38501542  1.06728107  1.92654494]]\n"
     ]
    }
   ],
   "source": [
    "R = [\n",
    "\n",
    "    [5,3,0,1],\n",
    "\n",
    "     [4,0,0,1],\n",
    "\n",
    "     [1,1,0,5],\n",
    "\n",
    "     [1,0,0,4],\n",
    "    \n",
    "     [1,2,0,5],\n",
    "\n",
    "    ]\n",
    "\n",
    "R = numpy.array(R)\n",
    "# N: num of User\n",
    "# N = len(R)\n",
    "# # M: num of Movie\n",
    "# M = len(R[0])\n",
    "# Num of Features\n",
    "K = 3\n",
    "nP, nQ = matrix_factorization_PALM(R, K)\n",
    "\n",
    "nR = numpy.dot(nP, nQ)\n",
    "print(nR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c379f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0c7eba83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 5, 0, ..., 0, 1, 4],\n",
       "       [2, 1, 5, ..., 4, 0, 5],\n",
       "       [2, 0, 2, ..., 5, 1, 0],\n",
       "       ...,\n",
       "       [1, 5, 2, ..., 2, 0, 1],\n",
       "       [2, 4, 2, ..., 4, 2, 3],\n",
       "       [2, 3, 2, ..., 3, 0, 2]], dtype=int8)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "matrix = np.random.randint(6, size=(100, 150), dtype=np.int8)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e4f077",
   "metadata": {},
   "source": [
    "# Working Great"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "d559a7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def matrix_factorization_PALM(R, k, max_iter=1000, tol=1e-4):\n",
    "    \"\"\"\n",
    "    Matrix factorization using Proximal Alternating Linear Minimization (PALM)\n",
    "    \n",
    "    Parameters:\n",
    "        R (np.ndarray): Input matrix to factorize\n",
    "        k (int): Number of latent factors\n",
    "        max_iter (int): Maximum number of iterations\n",
    "        tol (float): Tolerance for convergence\n",
    "        lambda_ (float): Regularization term\n",
    "        \n",
    "    Returns:\n",
    "        (np.ndarray, np.ndarray): The two factor matrices\n",
    "    \"\"\"\n",
    "    m, n = R.shape\n",
    "    X = np.random.rand(m, k) + 0.1 * np.random.randn(m, k)\n",
    "    Y = np.random.rand(k, n) + 0.1 * np.random.randn(k, n)\n",
    "    \n",
    "    # Set the step size\n",
    "#     eta = 1 / (np.linalg.norm(X, 2) * np.linalg.norm(Y, 2))\n",
    "#     print(eta)\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        \n",
    "        #Updating X\n",
    "        YYt = Y @ Y.T\n",
    "        RYt = R @ Y.T\n",
    "        L = max(np.linalg.norm(YYt), 1e-4)\n",
    "        eta = 1/(1.1*L)\n",
    "        grad_X = X @ YYt - RYt\n",
    "        X = X-grad_X * eta\n",
    "        \n",
    "        \n",
    "        #updating Y\n",
    "        XtX = X.T @ X\n",
    "        RtX = R.T @ X\n",
    "        L = max(np.linalg.norm(XtX), 1e-4)\n",
    "        eta = 1/(1.1*L)\n",
    "        grad_Yt = Y.T @ XtX - RtX\n",
    "        Yt = Y.T-grad_Yt *eta\n",
    "        \n",
    "        \n",
    "        \n",
    "        ell = np.linalg.norm(R - X @ Y)**2\n",
    "        ell0 = ell\n",
    "        # Check for convergence\n",
    "#         if (abs(ell - ell0) < tol):\n",
    "#             break    \n",
    "\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "3ff5afcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 2 1]\n",
      " [1 3 1 5]\n",
      " [0 1 4 4]\n",
      " [3 1 2 2]\n",
      " [2 4 0 4]]\n",
      "\n",
      "[[1.04014905 2.07265776 1.65702102 1.2911812 ]\n",
      " [0.7370133  2.5240728  3.24660168 3.09268713]\n",
      " [0.02580682 1.04670029 3.77955294 4.18715345]\n",
      " [2.98282984 0.96892896 2.14667048 1.87548062]\n",
      " [1.70543883 3.46693408 2.51632326 1.86370041]]\n"
     ]
    }
   ],
   "source": [
    "R = np.random.randint(6, size=(5, 4), dtype=np.int8)\n",
    "# N: num of User\n",
    "# N = len(R)\n",
    "# # M: num of Movie\n",
    "# M = len(R[0])\n",
    "# Num of Features\n",
    "print(R)\n",
    "print(\"\")\n",
    "K = 3\n",
    "nP, nQ = matrix_factorization_PALM(R, K)\n",
    "\n",
    "nR = numpy.dot(nP, nQ)\n",
    "print(nR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7b8a430f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 2, 0, ..., 0, 3, 2],\n",
       "       [5, 4, 5, ..., 1, 3, 0],\n",
       "       [5, 3, 3, ..., 3, 1, 4],\n",
       "       ...,\n",
       "       [5, 3, 1, ..., 4, 0, 1],\n",
       "       [1, 0, 4, ..., 2, 3, 4],\n",
       "       [2, 5, 3, ..., 3, 1, 3]], dtype=int8)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79c65fa1",
   "metadata": {},
   "source": [
    "# Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a9ef8bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def matrix_factorization_PALM(R, k, max_iter=100000, tol=1e-4, lambda_=0.1):\n",
    "    \"\"\"\n",
    "    Matrix factorization using Proximal Alternating Linear Minimization (PALM) with regularization\n",
    "    \n",
    "    Parameters:\n",
    "        R (np.ndarray): Input matrix to factorize\n",
    "        k (int): Number of latent factors\n",
    "        max_iter (int): Maximum number of iterations\n",
    "        tol (float): Tolerance for convergence\n",
    "        lambda_ (float): Regularization term\n",
    "        \n",
    "    Returns:\n",
    "        (np.ndarray, np.ndarray): The two factor matrices\n",
    "    \"\"\"\n",
    "    m, n = R.shape\n",
    "    X = np.random.rand(m, k)\n",
    "    Y = np.random.rand(k, n)\n",
    "    \n",
    "    # Set the step size\n",
    "    eta = 1 / (np.linalg.norm(X, 2) * np.linalg.norm(Y, 2))\n",
    "    #print(eta)\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        \n",
    "        #Updating X\n",
    "        YYt = Y @ Y.T\n",
    "        RYt = R @ Y.T\n",
    "        L = max(np.linalg.norm(YYt), 1e-4)\n",
    "        eta = 1/(1.1*L)\n",
    "        grad_X = X @ YYt - RYt + lambda_*X\n",
    "        X = X-grad_X * eta\n",
    "        \n",
    "        #updating Y\n",
    "        XtX = X.T @ X\n",
    "        RtX = R.T @ X\n",
    "        L = max(np.linalg.norm(XtX), 1e-4)\n",
    "        eta = 1/(1.1*L)\n",
    "        grad_Yt = Y.T @ XtX - RtX + lambda_*Y\n",
    "        Yt = Y.T-grad_Yt *eta\n",
    "        Y=Yt.T\n",
    "        \n",
    "        ell = np.linalg.norm(R - X @ Y)**2 + lambda_*(np.linalg.norm(X)**2 + np.linalg.norm(Y)**2)\n",
    "        ell0 = ell\n",
    "        # Check for convergence\n",
    "#         if (abs(ell - ell0) < tol):\n",
    "#             break    \n",
    "\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9c55efe5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,3) (3,4) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [145]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# N: num of User\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# N = len(R)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# # M: num of Movie\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# M = len(R[0])\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Num of Features\u001b[39;00m\n\u001b[1;32m     19\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m---> 20\u001b[0m nP, nQ \u001b[38;5;241m=\u001b[39m \u001b[43mmatrix_factorization_PALM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m nR \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mdot(nP, nQ)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(nR)\n",
      "Input \u001b[0;32mIn [144]\u001b[0m, in \u001b[0;36mmatrix_factorization_PALM\u001b[0;34m(R, k, max_iter, tol, lambda_)\u001b[0m\n\u001b[1;32m     38\u001b[0m L \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(XtX), \u001b[38;5;241m1e-4\u001b[39m)\n\u001b[1;32m     39\u001b[0m eta \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m1.1\u001b[39m\u001b[38;5;241m*\u001b[39mL)\n\u001b[0;32m---> 40\u001b[0m grad_Yt \u001b[38;5;241m=\u001b[39m \u001b[43mY\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mXtX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mRtX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlambda_\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mY\u001b[49m\n\u001b[1;32m     41\u001b[0m Yt \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m-\u001b[39mgrad_Yt \u001b[38;5;241m*\u001b[39meta\n\u001b[1;32m     42\u001b[0m Y\u001b[38;5;241m=\u001b[39mYt\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,3) (3,4) "
     ]
    }
   ],
   "source": [
    "R = [\n",
    "\n",
    "    [5,3,0,1],\n",
    "\n",
    "     [4,0,0,1],\n",
    "\n",
    "     [1,1,0,5],\n",
    "\n",
    "     [1,0,0,4],\n",
    "\n",
    "    ]\n",
    "\n",
    "R = numpy.array(R)\n",
    "# N: num of User\n",
    "# N = len(R)\n",
    "# # M: num of Movie\n",
    "# M = len(R[0])\n",
    "# Num of Features\n",
    "print(matrix)\n",
    "K = 3\n",
    "nP, nQ = matrix_factorization_PALM(matrix, K)\n",
    "\n",
    "nR = numpy.dot(nP, nQ)\n",
    "print(\"\")\n",
    "print(nR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2b366b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a5f028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47495c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def matrix_factorization_PALM(R, k, max_iter=100000, tol=1e-4, lambda_=0.1, alpha = 0.5, beta = 0.8, gamma = 0.9):\n",
    "    \"\"\"\n",
    "    Matrix factorization using Proximal Alternating Linear Minimization (PALM)\n",
    "    \n",
    "    Parameters:\n",
    "        R (np.ndarray): Input matrix to factorize\n",
    "        k (int): Number of latent factors\n",
    "        max_iter (int): Maximum number of iterations\n",
    "        tol (float): Tolerance for convergence\n",
    "        lambda_ (float): Regularization term\n",
    "        \n",
    "    Returns:\n",
    "        (np.ndarray, np.ndarray): The two factor matrices\n",
    "    \"\"\"\n",
    "    m, n = R.shape\n",
    "    X = np.random.rand(m, k) + 0.1 * np.random.randn(m, k)\n",
    "    Y = np.random.rand(k, n) + 0.1 * np.random.randn(k, n)\n",
    "\n",
    "    # Set the step size\n",
    "    eta = 1 / (np.linalg.norm(X, 2) * np.linalg.norm(Y, 2))\n",
    "    v_x = 0\n",
    "    v_y = 0\n",
    "    for i in range(max_iter):\n",
    "        X_old = X\n",
    "        Y_old = Y\n",
    "        YYt = Y @ Y.T\n",
    "        RYt = R @ Y.T\n",
    "        L = max(np.linalg.norm(YYt), 1e-4)\n",
    "        eta = 1/(1.1*L)\n",
    "        grad_X = (X @ YYt - RYt) + lambda_ * np.sign(X)\n",
    "        v_x = gamma*v_x + eta*grad_X\n",
    "        X = X-v_x\n",
    "        while (np.linalg.norm(R-X@Y)**2) > (np.linalg.norm(R-X_old@Y_old)**2- alpha*eta*(np.linalg.norm(grad_X)**2)):\n",
    "            eta = eta*beta\n",
    "            X = X_old - eta*grad_X\n",
    "            \n",
    "        X = np.maximum(X, lambda_)\n",
    "        XtX = X.T @ X\n",
    "        RtX = R.T @ X\n",
    "        L = max(np.linalg.norm(XtX), 1e-4)\n",
    "        eta = 1/(1.1*L)\n",
    "        grad_Yt = (Y.T @ XtX - RtX) + lambda_ * np.sign(Y)\n",
    "        v_y = gamma*v_y + eta*grad_Yt\n",
    "        Yt = Y.T-v_y\n",
    "        Y = Yt.T\n",
    "        while (np.linalg.norm(R-X@Y)**2) > (np.linalg.norm(R-X_old@Y_old)**2- alpha*eta*(np.l.linalg.norm(grad_Yt)**2)):\n",
    "            eta = eta*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "14b2edc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'Yt' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [203]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m6\u001b[39m, size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m150\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint8)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmatrix_factorization_PALM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [202]\u001b[0m, in \u001b[0;36mmatrix_factorization_PALM\u001b[0;34m(R, k, max_iter, tol, lambda_, alpha, beta, gamma)\u001b[0m\n\u001b[1;32m     44\u001b[0m grad_Yt \u001b[38;5;241m=\u001b[39m (Y\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m XtX \u001b[38;5;241m-\u001b[39m RtX) \u001b[38;5;241m+\u001b[39m lambda_ \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msign(Y\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m     45\u001b[0m v_y \u001b[38;5;241m=\u001b[39m gamma\u001b[38;5;241m*\u001b[39mv_y \u001b[38;5;241m+\u001b[39m eta\u001b[38;5;241m*\u001b[39mgrad_Yt\n\u001b[0;32m---> 46\u001b[0m Y \u001b[38;5;241m=\u001b[39m \u001b[43mYt\u001b[49m\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(R\u001b[38;5;241m-\u001b[39mX\u001b[38;5;129m@Y\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m>\u001b[39m (np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(R\u001b[38;5;241m-\u001b[39mX_old\u001b[38;5;129m@Y_old\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m-\u001b[39m alpha\u001b[38;5;241m*\u001b[39meta\u001b[38;5;241m*\u001b[39m(np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(grad_Yt)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)):\n\u001b[1;32m     48\u001b[0m     eta \u001b[38;5;241m=\u001b[39m eta\u001b[38;5;241m*\u001b[39mbeta\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'Yt' referenced before assignment"
     ]
    }
   ],
   "source": [
    "matrix = np.random.randint(6, size=(100, 150), dtype=np.int8)\n",
    "matrix_factorization_PALM(matrix,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "fea254ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.32652372  2.18816428  0.18504005  1.00294508]\n",
      " [ 3.46567149  1.32850063 -0.30280243  0.99518063]\n",
      " [ 1.19208569  0.52241748  0.10885441  5.00173251]\n",
      " [ 0.86190988  0.34333338 -0.07825527  3.9987545 ]\n",
      " [-0.05108206  1.1270053   4.97105194  3.99953927]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_357771/622531850.py:16: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  user_latent[user] = np.linalg.lstsq(item_latent, ratings[user])[0]\n",
      "/tmp/ipykernel_357771/622531850.py:20: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  item_latent[item] = np.linalg.lstsq(user_latent, ratings[:, item])[0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Step 1: Create a matrix of user-item ratings\n",
    "ratings = np.array([[5, 3, 0, 1], [4, 0, 0, 1], [1, 1, 0, 5], [1, 0, 0, 4], [0, 1, 5, 4]])\n",
    "\n",
    "# Step 2: Initialize matrices for user and item latent representations\n",
    "num_users, num_items = ratings.shape\n",
    "latent_dim = 3\n",
    "user_latent = np.random.random((num_users, latent_dim))\n",
    "item_latent = np.random.random((num_items, latent_dim))\n",
    "\n",
    "# Step 3 and 4: Iteratively update the user and item latent representations\n",
    "for i in range(100):\n",
    "    # Fix item latent representations and solve for user latent representations\n",
    "    for user in range(num_users):\n",
    "        user_latent[user] = np.linalg.lstsq(item_latent, ratings[user])[0]\n",
    "\n",
    "    # Fix user latent representations and solve for item latent representations\n",
    "    for item in range(num_items):\n",
    "        item_latent[item] = np.linalg.lstsq(user_latent, ratings[:, item])[0]\n",
    "\n",
    "# Step 5: Use the learned latent representations to make recommendations\n",
    "user_predictions = np.dot(user_latent, item_latent.T)\n",
    "print(user_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfb3afc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
